---
repo: fighting41love/funNLP
readme_filename: fighting41love_funNLP_README.md
stars: 74401
forks: 14890
watchers: 74401
contributors_count: 11
license: None
Header 1: LLM的数据集
---
| 资源名（Name）      | 描述（Description） | 链接     |
| :---        |    :----   |          :--- |
|   歧义数据集   |   能否正确的消除歧义是衡量大语言模型的一个重要指标。不过一直没有一个标准化的衡量方法，这篇论文提出了一个包含1,645个具有不同种类歧义的数据集及对应的评估方法。    |   github paper   |
|   thu指令训练数据   |    设计了一套流程来自动产生多样化高质量的多轮指令对话数据UltraChat，并进行了细致的人工后处理。现已将英文数据全部开源，共计150余万条，是开源社区数量最多的高质量指令数据之一   |   github    |
|   多模态数据集MMC4   |    5.8亿图片，1亿文档，400亿token   |   github    |
|  EleutherAI 数据   |   800g的文本语料给你整合好了免费下载，不知道trian出来的model质量如何，打算试试：    |    pile data    paper   |
|UltraChat|大规模、信息丰富、多样化的多轮对话数据|github|
|ConvFinQA金融数据问答||github|
|   The botbots dataset   |  一个包含对话内容的数据集，对话内容来自于两个ChatGPT实例(gpt-3.5-turbo)，CLT命令和对话提示来自GPT-4，覆盖多种情境和任务，生成成本约为35美元，可用于研究和训练更小的对话模型(如Alpaca)     |   github    |
|  alpaca_chinese_dataset - 人工精调的中文对话数据集    |       |   github    |
|CodeGPT-data|提高编程能力的关键在于数据。CodeGPT是通过GPT生成的用于GPT的代码对话数据集。现在公开了32K条中文数据，让模型更擅长编程|github|  
----