---
repo: fighting41love/funNLP
readme_filename: fighting41love_funNLP_README.md
stars: 74401
forks: 14890
watchers: 74401
contributors_count: 11
license: None
Header 1: 预训练语言模型&大模型
---
| 资源名（Name）      | 描述（Description） | 链接     |
| :---        |    :---  |          :--- |
|BMList|大模型大列表|github|
| bert论文中文翻译     |        | link   |
|    bert原作者的slides  |    |  link  |
| 文本分类实践     |        |  github  |
|  bert tutorial文本分类教程     |        | github |
| bert pytorch实现       |        |  github  |
|   bert pytorch实现      |        |  github  |
|  BERT生成句向量，BERT做文本分类、文本相似度计算     |        | github   |
|  bert、ELMO的图解     |        |  github  |
|  BERT Pre-trained models and downstream applications     |        |  github  |
|  语言/知识表示工具BERT & ERNIE      |        |   github  |
|    Kashgari中使用gpt-2语言模型    |        |  github   |
|     Facebook LAMA   |    用于分析预训练语言模型中包含的事实和常识知识的探针。语言模型分析，提供Transformer-XL/BERT/ELMo/GPT预训练语言模型的统一访问接口    |  github   |
|    中文的GPT2训练代码    |        |    github |
|   XLMFacebook的跨语言预训练语言模型     |        |   github  |
|    海量中文预训练ALBERT模型    |        |  github   |
|    Transformers 20    |    支持TensorFlow 20 和 PyTorch 的自然语言处理预训练语言模型(BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet…) 8种架构/33种预训练模型/102种语言   | github    |
|    8篇论文梳理BERT相关模型进展与反思    |        |    github |
|    法文RoBERTa预训练语言模型    |    用138GB语料训练的法文RoBERTa预训练语言模型    |   link  |
|     中文预训练 ELECTREA 模型    |    基于对抗学习 pretrain Chinese Model    |   github  |
|   albert-chinese-ner     |   用预训练语言模型ALBERT做中文NER    |   github  |
|    开源预训练语言模型合集    |        |  github   |
|   中文ELECTRA预训练模型     |        |  github   |
|    用Transformers(BERT, XLNet, Bart, Electra, Roberta, XLM-Roberta)预测下一个词(模型比较)    |        |  github   |
|   TensorFlow Hub     |    40+种语言的新语言模型(包括中文)    |  link   |
|   UER     | 基于不同语料、编码器、目标任务的中文预训练模型仓库（包括BERT、GPT、ELMO等）       |  github    |
|    开源预训练语言模型合集    |        |  github   |
|   多语言句向量包     |        |  github   |
|Language Model as a Service (LMaaS)|语言模型即服务|github|
|开源语言模型GPT-NeoX-20B|200亿参数，是目前最大的可公开访问的预训练通用自回归语言模型|github|
|中文科学文献数据集（CSL）|包含 396,209 篇中文核心期刊论文元信息 （标题、摘要、关键词、学科、门类）。CSL 数据集可以作为预训练语料，也可以构建许多NLP任务，例如文本摘要（标题预测）、 关键词生成和文本分类等。|github|
|大模型开发神器||github|