---
repo: fighting41love/funNLP
readme_filename: fighting41love_funNLP_README.md
stars: 74401
forks: 14890
watchers: 74401
contributors_count: 11
license: None
Header 1: 类ChatGPT的模型评测对比
---
| 资源名（Name）      | 描述（Description） | 链接     |
| :---        |    :----   |          :--- |
|   ChatALL：可以同时与多个AI聊天机器人（含清华、讯飞的产品）    |    可以同时与多个AI聊天机器人（如ChatGPT、Bing Chat、Bard、Alpaca、Vincuna、Claude、ChatGLM、MOSS、iFlytek Spark、ERNIE等）进行对话的工具。它可以并行发送提示给不同的AI机器人，帮助用户找到最好的回答   |  github-ChatALL  |
|  Chatbot Arena    |  实际场景用Elo rating对 LLM 进行基准测试 - 介绍了 Chatbot Arena，一种针对大型语言模型 (LLM) 的基准平台，采用匿名、随机的方式进行对抗评测，评测方式基于国际象棋等竞技游戏中广泛使用的 Elo rating system。发布了9个流行的开源 LLM 模型的 Elo rating 并推出排行榜。平台采用 FastChat 多模型服务系统，在多个语言下提供交互式界面，数据来源于用户投票。总结了 Chatbot Arena 的优点并计划提供更好的采样算法、排名和服务系统     |   截止2023年5月3日    |
|   类ChatGPT模型评测总结   |   大型语言模型(LLM)受到广泛关注，这些强大的模型能够理解复杂的信息，并对各种问题提供类人的回应。其中GPT-3和GPT-4表现最好，Flan-t5和Lit-LLaMA表现也不错。但要注意，模型商用可能需要付费和数据共享    |  blog     |
|   大型语言模型（LLMs）大盘点   |       |   blog    |
|   大模型评测方面的最新研究   |    长文本建模一直是ChaGPT令人惊艳的能力之一，我们以【篇章翻译】为实验场景，对大模型的篇章建模能力进行全面、细粒度的测试。   |  paper     |
|中文大模型评测工具&排行榜|C-Eval是一个全面的中文评估套件，适用于基础模型。它包含13948个多项选择题，涵盖52个不同的学科和四个难度级别，具体如下所示。请访问我们的网站或查阅我们的论文获取更多详细信息。|githubpaper|
|OpenCompass 大模型评测|OpenCompass 上海人工智能实验室开发的一款开源、高效、全面的评测大模型体系及开放平台，提供完整开源可复现的评测框架，支持大语言模型、多模态模型各类模型的一站式评测。利用分布式技术，即使面对千亿参数模型也能在数小时内完成评测。基于多个不同维度的高认可度数据集开放多样化的评测方式，包括零样本评测、小样本评测和思维链评测，全方位量化模型各个维度能力。|github  website|