---
repo: deepseek-ai/DeepSeek-V3
readme_filename: deepseek-ai_DeepSeek-V3_README.md
stars: 97889
forks: 15924
watchers: 97889
contributors_count: 21
license: MIT
Header 2: 6. How to Run Locally
Header 3: 6.3 Inference with LMDeploy (recommended)
---
LMDeploy, a flexible and high-performance inference and serving framework tailored for large language models, now supports DeepSeek-V3. It offers both offline pipeline processing and online deployment capabilities, seamlessly integrating with PyTorch-based workflows.  
For comprehensive step-by-step instructions on running DeepSeek-V3 with LMDeploy, please refer to here: 